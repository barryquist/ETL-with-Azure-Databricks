{"cells":[{"cell_type":"code","source":["dbutils.fs.help()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ef2cb3a9-bddc-4acd-83af-f3b523b2a08d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Mount Data Lake Gen2"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa11e3fd-5c76-4a83-a475-866d99311b5f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Mount DataLake Gen 2 to Databricks\n\n# gather relevant Service Principal keys\nSPApplicationID = dbutils.secrets.get(scope='TestScope', key='SPAppID')\nServicePrincipalKey = dbutils.secrets.get(scope='TestScope', key='SPsecretkey')\nDirectoryID = dbutils.secrets.get(scope='TestScope', key='SPDirID')\n\n\n# Create configurations for connection\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n           \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n           \"fs.azure.account.oauth2.client.id\": SPApplicationID,\n           \"fs.azure.account.oauth2.client.secret\": ServicePrincipalKey,\n           \"fs.azure.account.oauth2.client.endpoint\": DirectoryID}\n\n# Mount datalakegen2 onto databricks dbfs\ndbutils.fs.mount(\n  source = \"abfss://test@storageaccountdl1738.dfs.core.windows.net/\",\n  mount_point = \"/mnt/Testadl\",\n  extra_configs = configs)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7005dbc3-ab88-4fbe-933f-8658665e2469","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[17]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[17]: True"]}}],"execution_count":0},{"cell_type":"code","source":["#check files in mount point\n\ndbutils.fs.ls(\"/mnt/Testadl\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85f1866f-6500-4201-a2d3-07617cf1055f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[18]: [FileInfo(path='dbfs:/mnt/Testadl/pokemon.csv', name='pokemon.csv', size=45254, modificationTime=1672997333000)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[18]: [FileInfo(path='dbfs:/mnt/Testadl/pokemon.csv', name='pokemon.csv', size=45254, modificationTime=1672997333000)]"]}}],"execution_count":0},{"cell_type":"code","source":["# unmount storage system\n\ndbutils.fs.unmount('/mnt//')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a7e6013-9bbc-4ce9-8e22-edc0fefcdaa0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/mnt/TestMountBlobPython has been unmounted.\nOut[16]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/mnt/TestMountBlobPython has been unmounted.\nOut[16]: True"]}}],"execution_count":0},{"cell_type":"code","source":["# read data from mounted adlgen2 storage\n\ndf = spark.read.format(\"csv\")\\\n    .option(\"inferSchema\", True) \\\n    .option(\"header\", True) \\\n    .option(\"sep\", \",\") \\\n    .load(\"/mnt/Testadl/pokemon.csv\")\n\ndf.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9e773de0-de9b-4494-97bc-a7f627eec9c1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+----------+-------------+------+------+---------------+------+------+---+------+-------+-----+--------------+---------------+\n| id|   species|generation_id|height|weight|base_experience|type_1|type_2| hp|attack|defense|speed|special-attack|special-defense|\n+---+----------+-------------+------+------+---------------+------+------+---+------+-------+-----+--------------+---------------+\n|  1| bulbasaur|            1|   0.7|   6.9|             64| grass|poison| 45|    49|     49|   45|            65|             65|\n|  2|   ivysaur|            1|   1.0|  13.0|            142| grass|poison| 60|    62|     63|   60|            80|             80|\n|  3|  venusaur|            1|   2.0| 100.0|            236| grass|poison| 80|    82|     83|   80|           100|            100|\n|  4|charmander|            1|   0.6|   8.5|             62|  fire|  null| 39|    52|     43|   65|            60|             50|\n|  5|charmeleon|            1|   1.1|  19.0|            142|  fire|  null| 58|    64|     58|   80|            80|             65|\n|  6| charizard|            1|   1.7|  90.5|            240|  fire|flying| 78|    84|     78|  100|           109|             85|\n|  7|  squirtle|            1|   0.5|   9.0|             63| water|  null| 44|    48|     65|   43|            50|             64|\n|  8| wartortle|            1|   1.0|  22.5|            142| water|  null| 59|    63|     80|   58|            65|             80|\n|  9| blastoise|            1|   1.6|  85.5|            239| water|  null| 79|    83|    100|   78|            85|            105|\n| 10|  caterpie|            1|   0.3|   2.9|             39|   bug|  null| 45|    30|     35|   45|            20|             20|\n+---+----------+-------------+------+------+---------------+------+------+---+------+-------+-----+--------------+---------------+\nonly showing top 10 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------+-------------+------+------+---------------+------+------+---+------+-------+-----+--------------+---------------+\n| id|   species|generation_id|height|weight|base_experience|type_1|type_2| hp|attack|defense|speed|special-attack|special-defense|\n+---+----------+-------------+------+------+---------------+------+------+---+------+-------+-----+--------------+---------------+\n|  1| bulbasaur|            1|   0.7|   6.9|             64| grass|poison| 45|    49|     49|   45|            65|             65|\n|  2|   ivysaur|            1|   1.0|  13.0|            142| grass|poison| 60|    62|     63|   60|            80|             80|\n|  3|  venusaur|            1|   2.0| 100.0|            236| grass|poison| 80|    82|     83|   80|           100|            100|\n|  4|charmander|            1|   0.6|   8.5|             62|  fire|  null| 39|    52|     43|   65|            60|             50|\n|  5|charmeleon|            1|   1.1|  19.0|            142|  fire|  null| 58|    64|     58|   80|            80|             65|\n|  6| charizard|            1|   1.7|  90.5|            240|  fire|flying| 78|    84|     78|  100|           109|             85|\n|  7|  squirtle|            1|   0.5|   9.0|             63| water|  null| 44|    48|     65|   43|            50|             64|\n|  8| wartortle|            1|   1.0|  22.5|            142| water|  null| 59|    63|     80|   58|            65|             80|\n|  9| blastoise|            1|   1.6|  85.5|            239| water|  null| 79|    83|    100|   78|            85|            105|\n| 10|  caterpie|            1|   0.3|   2.9|             39|   bug|  null| 45|    30|     35|   45|            20|             20|\n+---+----------+-------------+------+------+---------------+------+------+---+------+-------+-----+--------------+---------------+\nonly showing top 10 rows\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Mounting Blob Storage"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bc4e607d-02af-4a7e-9f90-6a8a2386e9b1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Mount Blob Storage to Databricks DBFS\n\ndbutils.fs.mount(\n  source = \"wasbs://test-blob@storageaccountblob.blob.core.windows.net\",\n  mount_point = \"/mnt/TestMountBlobPython\",\n  extra_configs = {\"fs.azure.account.key.storageaccountblob.blob.core.windows.net\": dbutils.secrets.get(scope='testScope', key='blobAccountKey')}\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"265b0581-a98c-4c29-a4a8-3b8bbc3b3d2e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-2907708406896789>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Mount Blob Storage to Databricks DBFS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m dbutils.fs.mount(\n\u001B[0m\u001B[1;32m      4\u001B[0m   \u001B[0msource\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"wasbs://test-blob@storageaccountblob.blob.core.windows.net\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m   \u001B[0mmount_point\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"/mnt/TestMountBlobPython\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py\u001B[0m in \u001B[0;36mf_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m                     \u001B[0mexc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__context__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    361\u001B[0m                     \u001B[0mexc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__cause__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 362\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    364\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mf_with_exception_handling\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o380.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/TestMountBlobPython; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/TestMountBlobPython\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1004)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1030)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:541)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:636)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:657)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:398)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:147)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:396)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:393)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:66)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:441)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:426)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:66)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:631)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:550)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:66)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:541)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:511)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:66)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:130)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1024)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/TestMountBlobPython\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:487)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$1(MetadataManager.scala:852)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:633)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:841)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:495)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:120)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:347)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:306)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:544)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:639)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:660)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:401)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:399)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:396)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:444)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:429)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:634)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:553)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:544)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:514)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:956)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:956)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:872)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:502)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:477)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:372)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:401)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:399)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:396)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:56)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:444)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:429)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:56)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:372)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:167)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:477)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:374)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\n","errorSummary":"java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/TestMountBlobPython; nested exception is: ","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-2907708406896789>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Mount Blob Storage to Databricks DBFS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m dbutils.fs.mount(\n\u001B[0m\u001B[1;32m      4\u001B[0m   \u001B[0msource\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"wasbs://test-blob@storageaccountblob.blob.core.windows.net\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m   \u001B[0mmount_point\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"/mnt/TestMountBlobPython\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py\u001B[0m in \u001B[0;36mf_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m                     \u001B[0mexc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__context__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    361\u001B[0m                     \u001B[0mexc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__cause__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 362\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    364\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mf_with_exception_handling\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o380.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/TestMountBlobPython; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/TestMountBlobPython\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1004)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1030)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:541)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:636)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:657)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:398)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:147)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:396)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:393)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:66)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:441)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:426)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:66)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:631)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:550)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:66)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:541)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:511)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:66)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:130)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1024)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/TestMountBlobPython\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:487)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$1(MetadataManager.scala:852)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:633)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:841)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:495)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:120)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:347)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:306)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$2(ServerBackend.scala:119)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:146)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:116)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:544)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:639)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:660)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:401)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:399)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:396)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:444)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:429)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:634)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:553)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:24)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:544)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:514)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:24)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:115)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleRPC$2(JettyServer.scala:956)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:956)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:872)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2(JettyServer.scala:502)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$2$adapted(JettyServer.scala:477)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:372)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:401)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:399)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:396)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:56)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:444)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:429)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionTags(ActivityContextFactory.scala:56)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:372)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:167)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:477)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:374)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:539)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:80)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\t... 1 more\n"]}}],"execution_count":0},{"cell_type":"code","source":["#check files in mount point\n\ndbutils.fs.ls(\"/mnt/TestMountBlobPython\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2989bcf9-fb0e-4769-a664-1d3d9c46ec02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[21]: [FileInfo(path='dbfs:/mnt/TestMountBlobPython/201902-fordgobike-tripdata.csv', name='201902-fordgobike-tripdata.csv', size=39422395, modificationTime=1672766078000),\n FileInfo(path='dbfs:/mnt/TestMountBlobPython/sales_data.csv', name='sales_data.csv', size=22441174, modificationTime=1672766132000)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[21]: [FileInfo(path='dbfs:/mnt/TestMountBlobPython/201902-fordgobike-tripdata.csv', name='201902-fordgobike-tripdata.csv', size=39422395, modificationTime=1672766078000),\n FileInfo(path='dbfs:/mnt/TestMountBlobPython/sales_data.csv', name='sales_data.csv', size=22441174, modificationTime=1672766132000)]"]}}],"execution_count":0},{"cell_type":"code","source":["# unmount storage system\n\ndbutils.fs.unmount('/mnt/TestMountBlobPython')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1b6b4ead-903b-4475-b8bc-7a3e0b7e9f0b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/mnt/TestMountBlobPython has been unmounted.\nOut[13]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/mnt/TestMountBlobPython has been unmounted.\nOut[13]: True"]}}],"execution_count":0},{"cell_type":"code","source":["# check to see if Account Keys from Azure Secret Vault is redacted\n\nabd = dbutils.secrets.get(scope='testScope', key='blobAccountKey')\n\nprint(abd)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b2ee5637-f6e9-4d24-b27d-6e103b7aafaa","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Reading Data from the Mounted Blob Storage\n\ndf = spark.read.format(\"csv\")\\\n    .option(\"inferSchema\", True) \\\n    .option(\"header\", True) \\\n    .option(\"sep\", \",\") \\\n    .load(\"/mnt/TestMountBlobPython/sales_data.csv\")\n\ndf.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"79109122-9c98-4615-bb65-c506d7bdd67a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+--------+--------------------+----------------+----------+-------------------+--------------------+-----+------+--------------+----+\n|_c0|Order ID|             Product|Quantity Ordered|Price Each|         Order Date|    Purchase Address|Month| Sales|          City|Hour|\n+---+--------+--------------------+----------------+----------+-------------------+--------------------+-----+------+--------------+----+\n|  0|  295665|  Macbook Pro Laptop|               1|    1700.0|2019-12-30 00:01:00|136 Church St, Ne...|   12|1700.0| New York City|   0|\n|  1|  295666|  LG Washing Machine|               1|     600.0|2019-12-29 07:03:00|562 2nd St, New Y...|   12| 600.0| New York City|   7|\n|  2|  295667|USB-C Charging Cable|               1|     11.95|2019-12-12 18:21:00|277 Main St, New ...|   12| 11.95| New York City|  18|\n|  3|  295668|    27in FHD Monitor|               1|    149.99|2019-12-22 15:13:00|410 6th St, San F...|   12|149.99| San Francisco|  15|\n|  4|  295669|USB-C Charging Cable|               1|     11.95|2019-12-18 12:38:00|43 Hill St, Atlan...|   12| 11.95|       Atlanta|  12|\n|  5|  295670|AA Batteries (4-p...|               1|      3.84|2019-12-31 22:58:00|200 Jefferson St,...|   12|  3.84| New York City|  22|\n|  6|  295671|USB-C Charging Cable|               1|     11.95|2019-12-16 15:10:00|928 12th St, Port...|   12| 11.95|      Portland|  15|\n|  7|  295672|USB-C Charging Cable|               2|     11.95|2019-12-13 09:29:00|813 Hickory St, D...|   12|  23.9|        Dallas|   9|\n|  8|  295673|Bose SoundSport H...|               1|     99.99|2019-12-15 23:26:00|718 Wilson St, Da...|   12| 99.99|        Dallas|  23|\n|  9|  295674|AAA Batteries (4-...|               4|      2.99|2019-12-28 11:51:00|77 7th St, Dallas...|   12| 11.96|        Dallas|  11|\n+---+--------+--------------------+----------------+----------+-------------------+--------------------+-----+------+--------------+----+\nonly showing top 10 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+--------+--------------------+----------------+----------+-------------------+--------------------+-----+------+--------------+----+\n|_c0|Order ID|             Product|Quantity Ordered|Price Each|         Order Date|    Purchase Address|Month| Sales|          City|Hour|\n+---+--------+--------------------+----------------+----------+-------------------+--------------------+-----+------+--------------+----+\n|  0|  295665|  Macbook Pro Laptop|               1|    1700.0|2019-12-30 00:01:00|136 Church St, Ne...|   12|1700.0| New York City|   0|\n|  1|  295666|  LG Washing Machine|               1|     600.0|2019-12-29 07:03:00|562 2nd St, New Y...|   12| 600.0| New York City|   7|\n|  2|  295667|USB-C Charging Cable|               1|     11.95|2019-12-12 18:21:00|277 Main St, New ...|   12| 11.95| New York City|  18|\n|  3|  295668|    27in FHD Monitor|               1|    149.99|2019-12-22 15:13:00|410 6th St, San F...|   12|149.99| San Francisco|  15|\n|  4|  295669|USB-C Charging Cable|               1|     11.95|2019-12-18 12:38:00|43 Hill St, Atlan...|   12| 11.95|       Atlanta|  12|\n|  5|  295670|AA Batteries (4-p...|               1|      3.84|2019-12-31 22:58:00|200 Jefferson St,...|   12|  3.84| New York City|  22|\n|  6|  295671|USB-C Charging Cable|               1|     11.95|2019-12-16 15:10:00|928 12th St, Port...|   12| 11.95|      Portland|  15|\n|  7|  295672|USB-C Charging Cable|               2|     11.95|2019-12-13 09:29:00|813 Hickory St, D...|   12|  23.9|        Dallas|   9|\n|  8|  295673|Bose SoundSport H...|               1|     99.99|2019-12-15 23:26:00|718 Wilson St, Da...|   12| 99.99|        Dallas|  23|\n|  9|  295674|AAA Batteries (4-...|               4|      2.99|2019-12-28 11:51:00|77 7th St, Dallas...|   12| 11.96|        Dallas|  11|\n+---+--------+--------------------+----------------+----------+-------------------+--------------------+-----+------+--------------+----+\nonly showing top 10 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ee5d20c6-2653-4f5d-a979-5d1372bf0254","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Mounting Blob Storage & DataLake Gen 2 in Azure Databricks","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2907708406896785}},"nbformat":4,"nbformat_minor":0}
